{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n",
    "\n",
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. It's been running for many years, and is a major force in popular culture.\n",
    "\n",
    "Imagine that you want to compete on Jeopardy, and you're looking for any way to win. In this project, I'll work with a dataset of Jeopardy questions to figure out some patterns in the questions that could help one win.\n",
    "\n",
    "The dataset is named jeopardy.csv, and contains 20000 rows from the beginning of a full dataset of Jeopardy questions, which can be download [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "import re\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data and First Inspections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('jeopardy.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns have spaces in front of them. These need to be removed before continuing the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove empty whitespaces\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Show Number  19999 non-null  int64 \n",
      " 1   Air Date     19999 non-null  object\n",
      " 2   Round        19999 non-null  object\n",
      " 3   Category     19999 non-null  object\n",
      " 4   Value        19999 non-null  object\n",
      " 5   Question     19999 non-null  object\n",
      " 6   Answer       19999 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Air Date column contains the date the question was asked. Thus it needs to be converted to datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Show Number  19999 non-null  int64         \n",
      " 1   Air Date     19999 non-null  datetime64[ns]\n",
      " 2   Round        19999 non-null  object        \n",
      " 3   Category     19999 non-null  object        \n",
      " 4   Value        19999 non-null  object        \n",
      " 5   Question     19999 non-null  object        \n",
      " 6   Answer       19999 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df['Air Date'] = pd.to_datetime(df['Air Date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Columns\n",
    "\n",
    "In order to better analyze the `Question`, `Answer` and `Value` Columns, they need to be cleaned up. The cleaned up versions will be appended to new columns at the end of the dataframe:\n",
    "\n",
    "- `Question` becomes `clean_question`\n",
    "- `Answer` becomes `clean_answer`\n",
    "- `Value` becomes `clean_value`\n",
    "\n",
    "`Question` and `Answer` will be made lowercase and the punctuation will be removed. \n",
    "The same goes for `Value`, however this row also contains some none values which will transformed to text first and then set to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        for the last 8 years of his life galileo was u...\n",
       "1        no 2 1912 olympian football star at carlisle i...\n",
       "2        the city of yuma in this state has a record av...\n",
       "3        in 1963 live on the art linkletter show this c...\n",
       "4        signer of the dec of indep framer of the const...\n",
       "                               ...                        \n",
       "19994    of 8 12 or 18 the number of us states that tou...\n",
       "19995                             the new power generation\n",
       "19996    in 1589 he was appointed professor of mathemat...\n",
       "19997    before the grand jury she said im really sorry...\n",
       "19998    llamas are the heftiest south american members...\n",
       "Name: clean_question, Length: 19999, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('jeopardy.csv') # load data\n",
    "df.columns = df.columns.str.strip() # clean column names\n",
    "df['Air Date'] = pd.to_datetime(df['Air Date']) # convert Air Date to datetime-obj\n",
    "\n",
    "def normalize(string):\n",
    "    '''\n",
    "    take in string and:\n",
    "    - convert to lowercase\n",
    "    - remove punctuation\n",
    "    - return cleaned string\n",
    "    '''\n",
    "    string = string.lower() # lowercase\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    #string = re.sub(\"[^A-Za-z0-9\\s]\", \"\", string)\n",
    "    #string = re.sub(\"\\s+\", \" \", string)\n",
    "    return string\n",
    "\n",
    "def normalize_values(text):\n",
    "    '''\n",
    "    extra function for value column to deal with none values\n",
    "    '''\n",
    "    text = re.sub(\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text\n",
    "\n",
    "# apply normalize func to Question column and add result to clean_question column\n",
    "df['clean_question'] = df['Question'].apply(normalize) \n",
    "\n",
    "# apply normalize func to Answer column and add result to clean_answer column\n",
    "df['clean_answer'] = df['Answer'].apply(normalize)\n",
    "\n",
    "# apply normalize func to Value column and add result to clean_value column\n",
    "df['clean_value'] = df['Value'].apply(normalize_values)\n",
    "\n",
    "df['clean_question'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             copernicus\n",
       "1             jim thorpe\n",
       "2                arizona\n",
       "3              mcdonalds\n",
       "4             john adams\n",
       "              ...       \n",
       "19994                 18\n",
       "19995             prince\n",
       "19996            galileo\n",
       "19997    monica lewinsky\n",
       "19998             camels\n",
       "Name: clean_answer, Length: 19999, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of the data checks out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400     3892\n",
       "800     2980\n",
       "200     2784\n",
       "1000    1980\n",
       "600     1890\n",
       "        ... \n",
       "4100       1\n",
       "2021       1\n",
       "3300       1\n",
       "2900       1\n",
       "6100       1\n",
       "Name: clean_value, Length: 72, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no '$' signs - data checks out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Patterns in the Data\n",
    "\n",
    "Now I will try to prove or disprove some expected trends in the data. These are:\n",
    "\n",
    "- How often does the question contain the answer?\n",
    "- How often doe questions repeat themselves?\n",
    "- What are the value of the questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How big is the Chance of the Question containing the Answer?\n",
    "\n",
    "I will start by determinining the chance of the question containing the answer already. Therefore I will build a function `count_matches` which takes the row of df as an argument and returns the percentage of words contained in answer that are also contained in question. For this purpose I am removing 'the' from the strings as it is irrelevant and would distort the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>answer_in_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date      Round                         Category Value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      clean_question clean_answer  \\\n",
       "0  for the last 8 years of his life galileo was u...   copernicus   \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe   \n",
       "2  the city of yuma in this state has a record av...      arizona   \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds   \n",
       "4  signer of the dec of indep framer of the const...   john adams   \n",
       "\n",
       "   clean_value  answer_in_question  \n",
       "0          200                 0.0  \n",
       "1          200                 0.0  \n",
       "2          200                 0.0  \n",
       "3          200                 0.0  \n",
       "4          200                 0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_matches(row):\n",
    "    '''\n",
    "    takes row of datafraem\n",
    "    calculates the matches between (clean) answer and question rows\n",
    "    returns relative value\n",
    "    '''\n",
    "    \n",
    "    # split clean answer and question columns:\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    match_count = 0\n",
    "    \n",
    "    # remove 'the' from string-series as it is unnecessary:\n",
    "    if 'the' in split_answer:\n",
    "        #split_answer = re.sub(r'the', '', split_answer)\n",
    "        split_answer.remove(\"the\")\n",
    "    \n",
    "    # make sure no division by zero later on\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # finally count matches between split answer and question:\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "            \n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "df[\"answer_in_question\"] = df.apply(count_matches, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059001965249777744"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6% of the time, the quesiton is already in the answer. We can conclude that the chance is pretty low!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often are Questions Repeats of older ones?\n",
    "\n",
    "Now let's take a look at the chance that questions are repeated. To do this, I will use the following workflow:\n",
    "\n",
    "- Sort df in order of ascending `Air Date`.\n",
    "- Maintain a set called `terms_used` that will be empty initially.\n",
    "- Iterate through each row of df.\n",
    "- Split `clean_question` into words, remove any word shorter than 6 characters, and check if each word occurs in `terms_used`.\n",
    "    - If it does, increment a counter.\n",
    "    - Add each word to `terms_used`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6877209804150494\n"
     ]
    }
   ],
   "source": [
    "questions_overlap = [] # empty list to be filled with recuring questions\n",
    "terms_used = set() # sempty set\n",
    "\n",
    "df = df.sort_values(by='Air Date') # sort dataframe by date\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    split_question = row['clean_question'].split(' ') # split each row of clean_questions into list of strings\n",
    "    split_question = [q for q in split_question if len(q) > 5] # remove words with less than 6 characters\n",
    "    match_count = 0 # counting the no of words that match each other\n",
    "    \n",
    "    for word in split_question: # iterate through each word \n",
    "        if word in terms_used: # if word already used, match_count + 1\n",
    "            match_count += 1\n",
    "    for word in split_question: # add each word in split_question to terms_used\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0: # if split_questions contains a value, take average of match_count\n",
    "        match_count /= len(split_question)\n",
    "    \n",
    "    questions_overlap.append(match_count) # append match_count for each row to questions_overlap\n",
    "    \n",
    "df['questions_overlap'] = questions_overlap # append questions overlap to dataframe\n",
    "\n",
    "# print mean of questions_overlap\n",
    "print(df['questions_overlap'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like 69% of all questions are being recycled. Therefore it feels like a good strategy to look at old questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the Value of Questions\n",
    "\n",
    "Let's say you only want to study questions that pertain to high value questions instead of low value questions. This will help you earn more money when you're on Jeopardy.\n",
    "\n",
    "One can actually figure out which terms correspond to high-value questions using a chi-squared test. I'll first need to narrow down the questions into two categories:\n",
    "\n",
    "First some definitions:\n",
    "\n",
    "- Low value -- Any row where Value is less than 800.\n",
    "- High value -- Any row where Value is greater than 800.\n",
    "\n",
    "Again, I will loop through each of the terms in `terms_used` and:\n",
    "\n",
    "- Find the number of low value questions the word occurs in.\n",
    "- Find the number of high value questions the word occurs in.\n",
    "- Find the percentage of questions the word occurs in.\n",
    "- Based on the percentage of questions the word occurs in, find expected counts.\n",
    "- Compute the chi squared value based on the expected counts and the observed counts for high and low value questions.\n",
    "\n",
    "Afterwards I will be able to find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so I'll just do it for a small sample now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14265\n",
       "1     5734\n",
       "Name: high_value, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['clean_value'] = df['clean_value'].fillna(0)\n",
    "#df = df.dropna(how=\"all\")\n",
    "\n",
    "def determine_value(row):\n",
    "    '''\n",
    "    Function that returns 1 for high value question and 0 for low value ones. \n",
    "    It checks if clean_value is greater than 800 and: \n",
    "    returns 1 for yes and 0 for no\n",
    "    accepts row of dataframe\n",
    "    '''\n",
    "    value = 0\n",
    "    if row['clean_value'] > 800:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['high_value'] = df.apply(determine_value, axis = 1)\n",
    "df['high_value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code-cell I am randomly choosing 10 words to see how many of them are associated high and low value questions to serve as my `observed_expected` parameter for the chi-squared test. This means that the results will be fluctuating a bit each time the cell is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elburz', 'posters', 'shipwrecks', 'rocking', 'labrador', 'alamos', 'removal', 'robber', 'percent', 'morial']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 3),\n",
       " (3, 1),\n",
       " (1, 3),\n",
       " (0, 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_usage(term):\n",
    "    '''\n",
    "    function that takes in a word and counts how many times it is found within high and low value columns.\n",
    "    returns how many times the given word has been high and low counted\n",
    "    '''\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n",
    "# randomly pick ten elements of terms_used and append them to list comparison_terms:\n",
    "#terms_used_list = list(terms_used) # transform terms_used from set to list\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)] # randomly pick ten words\n",
    "print(comparison_terms)\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_usage(term))\n",
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can compute the expected counts and the chi-squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14265\n",
       "1     5734\n",
       "Name: high_value, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['high_value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of high values greater than 800: 5734\n",
      "sum of values smaller than 800: 14265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=1.205888538380652, pvalue=0.27214791766901714),\n",
       " Power_divergenceResult(statistic=4.198022975221989, pvalue=0.0404711362009595),\n",
       " Power_divergenceResult(statistic=0.02636443308440769, pvalue=0.871013484688921),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_value_count = df['high_value'].value_counts()[1] # how many high_values are 1\n",
    "low_value_count = df['high_value'].value_counts()[0] # how many high_values are 0\n",
    "\n",
    "print('sum of high values greater than 800: ' + str(high_value_count))\n",
    "print('sum of values smaller than 800: ' + str(low_value_count))\n",
    "\n",
    "# chi_squared hypothesis test\n",
    "chi_squared = []\n",
    "\n",
    "for i, entry in enumerate(observed_expected):\n",
    "    total = sum(entry)\n",
    "    total_prop = total / len(df)\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([entry[0], entry[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "    \n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Conclusion:\n",
    "\n",
    "In this project I looked at three major trends of the Jeopardy questions sample dataset. I was able to derive the following conclusions:\n",
    "\n",
    "- The chance of finding the answer in the question is pretty low. This was the case only 6% of the time.\n",
    "- The majority of questions (69%) were repeats of older ones. Therefore it feels like a good strategy to at least look at old questions.\n",
    "- The chi-squared test to figure out which terms correspond to high-value questions wasn't valid as the frequencies were all lower than 5. Thus its conclusion is irrelevant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
